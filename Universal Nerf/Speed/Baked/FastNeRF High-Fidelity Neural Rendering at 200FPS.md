# FastNeRF: High-Fidelity Neural Rendering at 200FPS

### Abstract

感觉2021年做加速的思路都非常相似，这篇也是主要是两个方面改进：

1. 在空间中对深辐射场图进行缓存
2. 能够以光线方向查询渲染图像中的像素值

### Introduction

这个方法在处理如何缓存神经网络输出的时候，同样认为**球谐波**是将R5的函数进行缓存的一个非常好的方法，使得积分产生**材料模型**和**照明模型的谐波系数**的点积。作者受此启发，将问题分解为两个独立的函数，一个函数采用多层感知器（MLP）的形式，该感知器以**空间中的位置**为条件，并返回由D分量参数化的深辐射映射。第二个功能是以**光线方向为条件**的 MLP，它为 D 深辐射图组件生成 D 权重。

如果假设$K$和$L$分别为位置和射线方向的箱数，直接缓存NeRF的内存复杂度为$O(K^3l^2)$, 相比之下缓存FastNeRF的复杂度为$O(K^3 *(1 + D * 3) + l^2 * D)$

### Method

![image-20231028144214856](C:\Users\admin\AppData\Roaming\Typora\typora-user-images\image-20231028144214856.png)

左边传统的Nerf是通过两个神经网络来进行的，首先输出该点密度$\sigma$ , 为了保证三维一致性，然后输入视角来输出该点的对应颜色，而FastNeRF的出发点并不一致，作者认为可以将颜色这一步骤修改为原始的计算机图形学的输出：
$$
L_o(p,d) = \int _{\Omega} f_r(p,d,w_i)L_i(p,w_i)(w_i,n)dw
$$
其中$L_o(p,d)$ 表示$p$点$d$方向离开的辐射，$f_r$ 代表该点材料特性的反射率函数，$L_i(p,w_i)$描述了光量，$n$对应于$p$方向的表面法线方向。

目前比较好的实操方法是球谐波去拟合$f_r(p,d,w_i)$ 和$L_i(p,w_i)$ 这两个函数。之后对于这两个球谐波的系数进行点积计算就可以了。

这就是作者idea的由来，将神经网络拆分为两个，一个仅和位置有关，代表该物体的反射率，另外一个仅和光线有关，代表光线量。输出就将两个神经网络的效果点积就可以。而且这样仅需要$R^3$和$R^2$的存储空间即可，而非$R^5$的存储空间。 
$$
F_{pos}: p \rightarrow {\sigma, (u,v,w)} \\
F_{dir}: d \rightarrow \beta
$$
上面的$(u,v,w)$都是一个$D$维度的分量。$\beta$是对应的权重。

然后对应的颜色的表示就是:
$$
c = (r,g,b) = \sum_{i=1}^D\beta_i(u_i,v_i,w_i) = \beta^T \cdot (u,v,w)
$$
（**个人理解其实就是同样的输入输出，不一样的中间计算方法，拆开是为了方便缓存**)

**缓存实现**

对于训练完成的NeRF模型，可以定义一个边界框**bouding box**，之后分别对该空间的k个(x, y, z)值进行均匀采样，然后对光线随机采样$l$个结果，然后通过这些p和d点积来生成结果。

### Implement

训练FastNeRF和NeRF是相同的，主要不同的是同样在**光线采样的时候用密度体积网格的碰撞来跳过空白空间**。



**这篇的对比和实验我觉得都不上一篇的PlenOctree, 既然球谐波为什么不一步到位呢，对比试验和效果都不太好**
